{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4261c33-e8d8-4d55-bd4f-c7e6ed258458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aec9c042-aa7f-42cc-95f4-a1bc60d875e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of items:\n",
      "['Pine' 'Oak' 'Rose' 'Daisy' 'Robin' 'Canary' 'Sunfish' 'Salmon']\n",
      "List of relations:\n",
      "['ISA' 'Is' 'Can' 'Has']\n",
      "List of attributes:\n",
      "['Living thing' 'Plant' 'Animal' 'Tree' 'Flower' 'Bird' 'Fish' 'Pine'\n",
      " 'Oak' 'Rose' 'Daisy' 'Robin' 'Canary' 'Sunfish' 'Salmon' 'Pretty' 'Big'\n",
      " 'Living' 'Green' 'Red' 'Yellow' 'Grow' 'Move' 'Swim' 'Fly' 'Sing' 'Skin'\n",
      " 'Roots' 'Leaves' 'Bark' 'Branch' 'Petals' 'Wings' 'Feathers' 'Gills'\n",
      " 'Scales']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/sem_items.txt\", \"r\") as fid:\n",
    "    names_items = np.array([l.strip() for l in fid.readlines()])\n",
    "with open(\"data/sem_relations.txt\", \"r\") as fid:\n",
    "    names_relations = np.array([l.strip() for l in fid.readlines()])\n",
    "with open(\"data/sem_attributes.txt\", \"r\") as fid:\n",
    "    names_attributes = np.array([l.strip() for l in fid.readlines()])\n",
    "\n",
    "nobj = len(names_items)\n",
    "nrel = len(names_relations)\n",
    "nattributes = len(names_attributes)\n",
    "print(\"List of items:\")\n",
    "print(names_items)\n",
    "print(\"List of relations:\")\n",
    "print(names_relations)\n",
    "print(\"List of attributes:\")\n",
    "print(names_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30dc433b-ec6f-4728-a655-99c6395f5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = np.loadtxt(\"data/sem_data.txt\")\n",
    "input_pats = torch.tensor(D[:, :len(names_items) + len(names_relations)], dtype=torch.float)\n",
    "output_pats = torch.tensor(D[:, len(names_items) + len(names_relations):], dtype=torch.float)\n",
    "\n",
    "# 生成问答对\n",
    "question_answer_pairs = []\n",
    "\n",
    "for i in range(input_pats.shape[0]):\n",
    "    input_v = input_pats[i].numpy().astype(\"bool\")\n",
    "    output_v = output_pats[i].numpy().astype(\"bool\")\n",
    "    \n",
    "    # 解码当前的物体和关系\n",
    "    item = names_items[input_v[:len(names_items)]][0]\n",
    "    relation = names_relations[input_v[len(names_items):].argmax()]\n",
    "    attributes = names_attributes[output_v]\n",
    "    \n",
    "    # 为每个属性生成问答对\n",
    "    for attribute in names_attributes:\n",
    "        question = f\"{item} {relation} {attribute}\"\n",
    "        answer = \"Yes\" if attribute in attributes else \"No\"\n",
    "        question_answer_pairs.append({\"Question\": question, \"Answer\": answer})\n",
    "# 保存问答对\n",
    "import pandas as pd\n",
    "qa_df = pd.DataFrame(question_answer_pairs)\n",
    "qa_df.to_csv(\"processed_qa_pairs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c590803b-af69-4c37-85e6-8d764c12bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小: 41\n",
      "训练集大小: 1152\n",
      "测试集大小: 230\n",
      "训练集示例问题: [22  3  6  0]\n",
      "训练集示例答案: 0\n"
     ]
    }
   ],
   "source": [
    "# 读取生成的问答对数据\n",
    "qa_df = pd.read_csv(\"processed_qa_pairs.csv\")  # 请确保路径正确\n",
    "\n",
    "# 提取问题和答案\n",
    "questions = qa_df['Question'].values  # 问题列表\n",
    "answers = qa_df['Answer'].map({\"Yes\": 1, \"No\": 0}).values  # 标签列表，\"Yes\" -> 1, \"No\" -> 0\n",
    "\n",
    "# 构建词表\n",
    "all_words = set(word for question in questions for word in question.split())  # 统计所有单词\n",
    "vocab = {word: idx + 1 for idx, word in enumerate(all_words)}  # 给每个单词分配索引（从1开始）\n",
    "vocab_size = len(vocab) + 1  # +1 是为了包括填充的索引0\n",
    "\n",
    "# 打印词表大小\n",
    "print(f\"词表大小: {vocab_size}\")\n",
    "\n",
    "# 定义函数：将问题转化为 One-hot 编码向量\n",
    "def one_hot_encode_question(question, vocab, max_len=4):\n",
    "    tokens = question.split()  # 分割单词\n",
    "    indices = [vocab[word] for word in tokens if word in vocab]  # 将每个单词转化为索引\n",
    "    if len(indices) > max_len:\n",
    "        print(\"question length over max length\")\n",
    "        indices = indices[:max_len]  # 如果长度超过 max_len，截断\n",
    "    else:\n",
    "        indices += [0] * (max_len - len(indices))  # 如果长度不足 max_len，用0填充\n",
    "    return indices\n",
    "\n",
    "# 转换所有问题\n",
    "max_len = 4  # 设置序列的最大长度\n",
    "encoded_questions = np.array([one_hot_encode_question(q, vocab, max_len) for q in questions])\n",
    "\n",
    "# 转换答案为 NumPy 数组\n",
    "answers = np.array(answers)\n",
    "\n",
    "# 数据分割\n",
    "test_size = 0.2  # 测试集比例\n",
    "num_samples = len(encoded_questions)  # 样本总数\n",
    "num_test_samples = int(num_samples * test_size)  # 测试集样本数\n",
    "\n",
    "# 随机打乱数据索引\n",
    "indices = np.arange(num_samples)  # 样本索引\n",
    "np.random.seed(42)  # 固定随机种子，确保结果可复现\n",
    "np.random.shuffle(indices)  # 打乱索引\n",
    "\n",
    "# 按索引划分训练集和测试集\n",
    "# train_indices = indices[:-num_test_samples]  # 训练集索引\n",
    "train_indices = indices  # 训练集索引\n",
    "\n",
    "test_indices = indices[-num_test_samples:]   # 测试集索引\n",
    "\n",
    "train_questions = encoded_questions[train_indices]  # 训练集问题\n",
    "train_answers = answers[train_indices]  # 训练集答案\n",
    "test_questions = encoded_questions[test_indices]  # 测试集问题\n",
    "test_answers = answers[test_indices]  # 测试集答案\n",
    "\n",
    "# 打印训练集和测试集大小\n",
    "print(f\"训练集大小: {len(train_questions)}\")\n",
    "print(f\"测试集大小: {len(test_questions)}\")\n",
    "\n",
    "# 检查数据示例\n",
    "print(\"训练集示例问题:\", train_questions[0])\n",
    "print(\"训练集示例答案:\", train_answers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eca293ff-4a8e-4831-b95b-17e587c5e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, questions, answers):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.questions[idx], dtype=torch.long), torch.tensor(self.answers[idx], dtype=torch.float)\n",
    "\n",
    "# 定义 RNN 模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # 嵌入层\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)  # LSTM 层\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # 全连接层\n",
    "        self.sigmoid = nn.Sigmoid()  # 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # 输入嵌入层\n",
    "        _, (hidden, _) = self.rnn(x)  # LSTM 的输出\n",
    "        x = self.fc(hidden[-1])  # 全连接层，使用最后一个隐藏状态\n",
    "        return self.sigmoid(x)  # 输出概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3063f991-834a-415f-9548-634f8877d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/5000, Loss: 0.3067\n",
      "Epoch 200/5000, Loss: 0.2719\n",
      "Epoch 300/5000, Loss: 0.2678\n",
      "Epoch 400/5000, Loss: 0.2640\n",
      "Epoch 500/5000, Loss: 0.2588\n",
      "Epoch 600/5000, Loss: 0.2492\n",
      "Epoch 700/5000, Loss: 0.2241\n",
      "Epoch 800/5000, Loss: 0.1771\n",
      "Epoch 900/5000, Loss: 0.1202\n",
      "Epoch 1000/5000, Loss: 0.0729\n",
      "Epoch 1100/5000, Loss: 0.0397\n",
      "Epoch 1200/5000, Loss: 0.0215\n",
      "Epoch 1300/5000, Loss: 0.0124\n",
      "Epoch 1400/5000, Loss: 0.0077\n",
      "Epoch 1500/5000, Loss: 0.0053\n",
      "Epoch 1600/5000, Loss: 0.0039\n",
      "Epoch 1700/5000, Loss: 0.0030\n",
      "Epoch 1800/5000, Loss: 0.0024\n",
      "Epoch 1900/5000, Loss: 0.0020\n",
      "Epoch 2000/5000, Loss: 0.0017\n",
      "Epoch 2100/5000, Loss: 0.0014\n",
      "Epoch 2200/5000, Loss: 0.0012\n",
      "Epoch 2300/5000, Loss: 0.0011\n",
      "Epoch 2400/5000, Loss: 0.0009\n",
      "Epoch 2500/5000, Loss: 0.0008\n",
      "Epoch 2600/5000, Loss: 0.0007\n",
      "Epoch 2700/5000, Loss: 0.0007\n",
      "Epoch 2800/5000, Loss: 0.0006\n",
      "Epoch 2900/5000, Loss: 0.0006\n",
      "Epoch 3000/5000, Loss: 0.0005\n",
      "Epoch 3100/5000, Loss: 0.0005\n",
      "Epoch 3200/5000, Loss: 0.0004\n",
      "Epoch 3300/5000, Loss: 0.0004\n",
      "Epoch 3400/5000, Loss: 0.0004\n",
      "Epoch 3500/5000, Loss: 0.0003\n",
      "Epoch 3600/5000, Loss: 0.0003\n",
      "Epoch 3700/5000, Loss: 0.0003\n",
      "Epoch 3800/5000, Loss: 0.0003\n",
      "Epoch 3900/5000, Loss: 0.0002\n",
      "Epoch 4000/5000, Loss: 0.0002\n",
      "Epoch 4100/5000, Loss: 0.0002\n",
      "Epoch 4200/5000, Loss: 0.0002\n",
      "Epoch 4300/5000, Loss: 0.0002\n",
      "Epoch 4400/5000, Loss: 0.0002\n",
      "Epoch 4500/5000, Loss: 0.0002\n",
      "Epoch 4600/5000, Loss: 0.0001\n",
      "Epoch 4700/5000, Loss: 0.0001\n",
      "Epoch 4800/5000, Loss: 0.0001\n",
      "Epoch 4900/5000, Loss: 0.0001\n",
      "Epoch 5000/5000, Loss: 0.0001\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "vocab_size = len(vocab) + 1  # 词汇表大小，包括填充索引\n",
    "embed_dim = 10  # 嵌入维度\n",
    "hidden_dim = 30  # 隐藏层维度\n",
    "batch_size = 1152  # 批大小\n",
    "epochs = 5000  # 训练轮数\n",
    "learning_rate = 0.0005  # 学习率\n",
    "\n",
    "# 数据加载\n",
    "train_dataset = QADataset(train_questions, train_answers)\n",
    "test_dataset = QADataset(test_questions, test_answers)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = RNNModel(vocab_size, embed_dim, hidden_dim).to(device)\n",
    "criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练函数\n",
    "# def train_model(model, train_loader, criterion, optimizer, epochs):\n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         epoch_loss = 0\n",
    "#         for questions, answers in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(questions).squeeze()  # 模型输出\n",
    "#             loss = criterion(outputs, answers)  # 计算损失\n",
    "#             loss.backward()  # 反向传播\n",
    "#             optimizer.step()  # 更新参数\n",
    "#             epoch_loss += loss.item()\n",
    "#         print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "def create_query_questions():\n",
    "    \"\"\"创建分层查询问题\"\"\"\n",
    "    # 第一层：基础概念查询\n",
    "    layer1_questions = []\n",
    "    basic_concepts = ['Living thing', 'Plant', 'Animal']\n",
    "    for item in names_items:\n",
    "        for concept in basic_concepts:\n",
    "            layer1_questions.append(f\"{item} ISA {concept}\")\n",
    "    \n",
    "    # 第二层：类别特征查询\n",
    "    layer2_questions = []\n",
    "    categories = ['Bird', 'Fish', 'Tree', 'Flower']\n",
    "    for item in names_items:\n",
    "        for category in categories:\n",
    "            layer2_questions.append(f\"{item} ISA {category}\")\n",
    "    \n",
    "    # 第三层：具体实例查询\n",
    "    layer3_questions = []\n",
    "    for item in names_items:\n",
    "        for target_item in names_items:\n",
    "            layer3_questions.append(f\"{item} ISA {target_item}\")\n",
    "    \n",
    "    # 第四层：属性查询\n",
    "    layer4_questions = []\n",
    "    properties = ['Pretty', 'Big', 'Living', 'Green', 'Red', 'Yellow', 'Grow', \n",
    "                 'Move', 'Swim', 'Fly', 'Sing', 'Skin', 'Roots', 'Leaves', \n",
    "                 'Bark', 'Branch', 'Petals', 'Wings', 'Feathers', 'Gills', 'Scales']\n",
    "    relations = ['Is', 'Can', 'Has']\n",
    "    for item in names_items:\n",
    "        for relation in relations:\n",
    "            for prop in properties:\n",
    "                layer4_questions.append(f\"{item} {relation} {prop}\")\n",
    "    \n",
    "    return layer1_questions, layer2_questions, layer3_questions, layer4_questions\n",
    "\n",
    "def get_all_representations(model, questions, vocab):\n",
    "    \"\"\"\n",
    "    获取问题在模型中的所有关键表征\n",
    "    \n",
    "    Args:\n",
    "        model: 训练的神经网络模型\n",
    "        questions: 查询问题列表\n",
    "        vocab: 词汇表字典\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含不同层表征的字典，包括：\n",
    "            - word_embeddings: 每个词的嵌入向量\n",
    "            - sentence_embeddings: 整个句子的嵌入表征\n",
    "            - lstm_hidden_states: LSTM所有时间步的隐藏状态\n",
    "            - lstm_final_state: LSTM最后时间步的隐藏状态\n",
    "            - cell_states: LSTM的细胞状态\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # 将问题转换为模型输入格式\n",
    "    encoded_questions = np.array([one_hot_encode_question(q, vocab) for q in questions])\n",
    "    question_tensors = torch.tensor(encoded_questions, dtype=torch.long).to(device)\n",
    "    \n",
    "    representations = {}\n",
    "    with torch.no_grad():\n",
    "        # 1. 获取句子进入嵌入层后得到的向量，每一列都是一个词\n",
    "        word_embeddings = model.embedding(question_tensors)\n",
    "        representations['word_embeddings'] = word_embeddings.cpu().numpy()\n",
    "\n",
    "        # 2. 计算句子级别的嵌入表征（通过平均词嵌入）（感觉没什么用先留着）\n",
    "        sentence_embeddings = word_embeddings.mean(dim=1)\n",
    "\n",
    "        representations['sentence_embeddings'] = sentence_embeddings.cpu().numpy()\n",
    "        \n",
    "        # 3. 获取LSTM的所有隐藏状态和细胞状态\n",
    "        lstm_out, (hidden_states, cell_states) = model.rnn(word_embeddings)\n",
    "        \n",
    "        # 保存所有时间步的隐藏状态\n",
    "        representations['lstm_hidden_states'] = lstm_out.cpu().numpy()\n",
    "        \n",
    "        # 保存最后一个时间步的隐藏状态\n",
    "        representations['lstm_final_state'] = hidden_states[-1].cpu().numpy()\n",
    "        \n",
    "        # 保存细胞状态\n",
    "        representations['cell_states'] = cell_states[-1].cpu().numpy()\n",
    "    \n",
    "    return representations\n",
    "\n",
    "def semantic_analysis_enhanced(model, epoch):\n",
    "    \"\"\"\n",
    "    增强版语义分析，记录更多层次的神经网络表征\n",
    "    \n",
    "    Args:\n",
    "        model: 训练的神经网络模型\n",
    "        epoch: 当前训练轮次\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含完整分析结果的字典\n",
    "    \"\"\"\n",
    "    # 创建分层查询问题\n",
    "    layer1_q, layer2_q, layer3_q, layer4_q = create_query_questions()\n",
    "    \n",
    "    # 获取每层问题的完整表征\n",
    "    layer1_repr = get_all_representations(model, layer1_q, vocab)\n",
    "    layer2_repr = get_all_representations(model, layer2_q, vocab)\n",
    "    layer3_repr = get_all_representations(model, layer3_q, vocab)\n",
    "    layer4_repr = get_all_representations(model, layer4_q, vocab)\n",
    "    \n",
    "    # 获取模型预测结果\n",
    "    layer1_answers = get_model_predictions(model, layer1_q)\n",
    "    layer2_answers = get_model_predictions(model, layer2_q)\n",
    "    layer3_answers = get_model_predictions(model, layer3_q)\n",
    "    layer4_answers = get_model_predictions(model, layer4_q)\n",
    "    \n",
    "    # 构建完整的分析结果\n",
    "    results = {\n",
    "        'epoch': epoch,\n",
    "        'layer1': {\n",
    "            'representations': layer1_repr,\n",
    "            'answers': layer1_answers,\n",
    "            'questions': layer1_q\n",
    "        },\n",
    "        'layer2': {\n",
    "            'representations': layer2_repr,\n",
    "            'answers': layer2_answers,\n",
    "            'questions': layer2_q\n",
    "        },\n",
    "        'layer3': {\n",
    "            'representations': layer3_repr,\n",
    "            'answers': layer3_answers,\n",
    "            'questions': layer3_q\n",
    "        },\n",
    "        'layer4': {\n",
    "            'representations': layer4_repr,\n",
    "            'answers': layer4_answers,\n",
    "            'questions': layer4_q\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_model_predictions(model, questions):\n",
    "    \"\"\"获取模型对问题的预测结果\"\"\"\n",
    "    model.eval()\n",
    "    encoded_questions = np.array([one_hot_encode_question(q, vocab) for q in questions])\n",
    "    question_tensors = torch.tensor(encoded_questions, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(question_tensors).squeeze()\n",
    "        # predictions = (outputs > 0.5).cpu().numpy()\n",
    "        predictions = (outputs).cpu().numpy()\n",
    "\n",
    "    return predictions\n",
    "def print_analysis_summary(results):\n",
    "    # \"\"\"\n",
    "    # 打印语义分析的基本统计信息\n",
    "    \n",
    "    # Args:\n",
    "    #     results: 语义分析结果字典\n",
    "    # \"\"\"\n",
    "    # for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    #     layer_data = results[layer_name]\n",
    "    #     answers = layer_data['answers']\n",
    "    #     positive_rate = answers.mean() * 100\n",
    "        \n",
    "    #     print(f\"\\n{layer_name} Summary:\")\n",
    "    #     print(f\"Positive answer rate: {positive_rate:.2f}%\")\n",
    "        \n",
    "    #     # 分析词嵌入的统计特征\n",
    "    #     word_embeddings = layer_data['representations']['word_embeddings']\n",
    "    #     embedding_mean = np.mean(word_embeddings)\n",
    "    #     embedding_std = np.std(word_embeddings)\n",
    "    #     print(f\"Word embedding stats - Mean: {embedding_mean:.4f}, Std: {embedding_std:.4f}\")\n",
    "        \n",
    "    #     # 分析LSTM隐藏状态的统计特征\n",
    "    #     hidden_states = layer_data['representations']['lstm_hidden_states']\n",
    "    #     hidden_mean = np.mean(hidden_states)\n",
    "    #     hidden_std = np.std(hidden_states)\n",
    "    #     print(f\"LSTM hidden state stats - Mean: {hidden_mean:.4f}, Std: {hidden_std:.4f}\")\n",
    "    pass\n",
    "def modified_train_model_enhanced(model, train_loader, criterion, optimizer, epochs):\n",
    "    \"\"\"\n",
    "    增强版训练函数，包含更详细的语义分析\n",
    "    \n",
    "    Args:\n",
    "        model: 神经网络模型\n",
    "        train_loader: 训练数据加载器\n",
    "        criterion: 损失函数\n",
    "        optimizer: 优化器\n",
    "        epochs: 训练轮数\n",
    "    \n",
    "    Returns:\n",
    "        list: 包含所有语义分析结果的列表\n",
    "    \"\"\"\n",
    "    semantic_results = []\n",
    "    analysis_frequency = 100  # 每100个epoch进行一次分析\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for questions, answers in train_loader:\n",
    "            questions, answers = questions.to(device), answers.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(questions).squeeze()\n",
    "            loss = criterion(outputs, answers)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # 定期进行语义分析\n",
    "        if (epoch + 1) % analysis_frequency == 0:\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            # 进行增强版语义分析\n",
    "            results = semantic_analysis_enhanced(model, epoch + 1)\n",
    "            semantic_results.append(results)\n",
    "            \n",
    "            # 保存分析结果\n",
    "            save_results(results, f\"semantic_analysis_enhanced_epoch_{epoch+1}.pkl\")\n",
    "            \n",
    "            # 计算和打印一些基本统计信息\n",
    "            print_analysis_summary(results)\n",
    "    \n",
    "    return semantic_results\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"保存分析结果到文件\"\"\"\n",
    "    import pickle\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "# 测试函数\n",
    "# def evaluate_model(model, test_loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for questions, answers in test_loader:\n",
    "#             outputs = model(questions).squeeze()\n",
    "#             predictions = (outputs > 0.5).float()  # 概率 > 0.5 视为正类\n",
    "#             correct += (predictions == answers).sum().item()\n",
    "#             total += answers.size(0)\n",
    "#     accuracy = correct / total * 100\n",
    "#     print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for questions, answers in test_loader:\n",
    "            questions, answers = questions.to(device), answers.to(device)  # Move to GPU\n",
    "            outputs = model(questions).squeeze()\n",
    "            predictions = (outputs > 0.5).float()  # Probability > 0.5 as positive class\n",
    "            correct += (predictions == answers).sum().item()\n",
    "            total += answers.size(0)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "# 训练和评估模型\n",
    "# 使用修改后的训练函数\n",
    "semantic_results = modified_train_model_enhanced(model, train_loader, criterion, optimizer, epochs)\n",
    "evaluate_model(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b8be89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pine ISA Living thing' 'Pine ISA Plant' 'Pine ISA Animal' ...\n",
      " 'Salmon Has Feathers' 'Salmon Has Gills' 'Salmon Has Scales']\n",
      "1\n",
      "['Pine ISA Living thing', 'Pine ISA Plant', 'Pine ISA Tree', 'Pine ISA Pine', 'Pine Is Big', 'Pine Is Living', 'Pine Is Green', 'Pine Can Grow', 'Pine Has Roots', 'Pine Has Bark', 'Pine Has Branch', 'Oak ISA Living thing', 'Oak ISA Plant', 'Oak ISA Tree', 'Oak ISA Oak', 'Oak Is Big', 'Oak Is Living', 'Oak Can Grow', 'Oak Has Roots', 'Oak Has Leaves', 'Oak Has Bark', 'Oak Has Branch', 'Rose ISA Living thing', 'Rose ISA Plant', 'Rose ISA Flower', 'Rose ISA Rose', 'Rose Is Pretty', 'Rose Is Living', 'Rose Is Red', 'Rose Can Grow', 'Rose Has Roots', 'Rose Has Leaves', 'Rose Has Petals', 'Daisy ISA Living thing', 'Daisy ISA Plant', 'Daisy ISA Flower', 'Daisy ISA Daisy', 'Daisy Is Pretty', 'Daisy Is Living', 'Daisy Is Yellow', 'Daisy Can Grow', 'Daisy Has Roots', 'Daisy Has Leaves', 'Daisy Has Petals', 'Robin ISA Living thing', 'Robin ISA Animal', 'Robin ISA Bird', 'Robin ISA Robin', 'Robin Is Living', 'Robin Is Red', 'Robin Can Grow', 'Robin Can Move', 'Robin Can Fly', 'Robin Has Skin', 'Robin Has Wings', 'Robin Has Feathers', 'Canary ISA Living thing', 'Canary ISA Animal', 'Canary ISA Bird', 'Canary ISA Canary', 'Canary Is Living', 'Canary Is Yellow', 'Canary Can Grow', 'Canary Can Move', 'Canary Can Fly', 'Canary Can Sing', 'Canary Has Skin', 'Canary Has Wings', 'Canary Has Feathers', 'Sunfish ISA Living thing', 'Sunfish ISA Animal', 'Sunfish ISA Fish', 'Sunfish ISA Sunfish', 'Sunfish Is Living', 'Sunfish Is Yellow', 'Sunfish Can Grow', 'Sunfish Can Move', 'Sunfish Can Swim', 'Sunfish Has Skin', 'Sunfish Has Gills', 'Sunfish Has Scales', 'Salmon ISA Living thing', 'Salmon ISA Animal', 'Salmon ISA Fish', 'Salmon ISA Salmon', 'Salmon Is Living', 'Salmon Is Red', 'Salmon Can Grow', 'Salmon Can Move', 'Salmon Can Swim', 'Salmon Has Skin', 'Salmon Has Gills', 'Salmon Has Scales']\n",
      "['Living ISA Pine', 'Plant ISA Pine', 'Tree ISA Pine', 'Pine ISA Pine', 'Big Is Pine', 'Living Is Pine', 'Green Is Pine', 'Grow Can Pine', 'Roots Has Pine', 'Bark Has Pine', 'Branch Has Pine', 'Living ISA Oak', 'Plant ISA Oak', 'Tree ISA Oak', 'Oak ISA Oak', 'Big Is Oak', 'Living Is Oak', 'Grow Can Oak', 'Roots Has Oak', 'Leaves Has Oak', 'Bark Has Oak', 'Branch Has Oak', 'Living ISA Rose', 'Plant ISA Rose', 'Flower ISA Rose', 'Rose ISA Rose', 'Pretty Is Rose', 'Living Is Rose', 'Red Is Rose', 'Grow Can Rose', 'Roots Has Rose', 'Leaves Has Rose', 'Petals Has Rose', 'Living ISA Daisy', 'Plant ISA Daisy', 'Flower ISA Daisy', 'Daisy ISA Daisy', 'Pretty Is Daisy', 'Living Is Daisy', 'Yellow Is Daisy', 'Grow Can Daisy', 'Roots Has Daisy', 'Leaves Has Daisy', 'Petals Has Daisy', 'Living ISA Robin', 'Animal ISA Robin', 'Bird ISA Robin', 'Robin ISA Robin', 'Living Is Robin', 'Red Is Robin', 'Grow Can Robin', 'Move Can Robin', 'Fly Can Robin', 'Skin Has Robin', 'Wings Has Robin', 'Feathers Has Robin', 'Living ISA Canary', 'Animal ISA Canary', 'Bird ISA Canary', 'Canary ISA Canary', 'Living Is Canary', 'Yellow Is Canary', 'Grow Can Canary', 'Move Can Canary', 'Fly Can Canary', 'Sing Can Canary', 'Skin Has Canary', 'Wings Has Canary', 'Feathers Has Canary', 'Living ISA Sunfish', 'Animal ISA Sunfish', 'Fish ISA Sunfish', 'Sunfish ISA Sunfish', 'Living Is Sunfish', 'Yellow Is Sunfish', 'Grow Can Sunfish', 'Move Can Sunfish', 'Swim Can Sunfish', 'Skin Has Sunfish', 'Gills Has Sunfish', 'Scales Has Sunfish', 'Living ISA Salmon', 'Animal ISA Salmon', 'Fish ISA Salmon', 'Salmon ISA Salmon', 'Living Is Salmon', 'Red Is Salmon', 'Grow Can Salmon', 'Move Can Salmon', 'Swim Can Salmon', 'Skin Has Salmon', 'Gills Has Salmon', 'Scales Has Salmon']\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.13978494623655913\n"
     ]
    }
   ],
   "source": [
    "def preprocess_question(question, vocab, max_len=4):\n",
    "    \"\"\"\n",
    "    将输入问题转换为模型可处理的格式。\n",
    "    \n",
    "    Args:\n",
    "        question (str): 输入问题，例如 \"Pine ISA Tree\"\n",
    "        vocab (dict): 词汇表，单词到索引的映射\n",
    "        max_len (int): 问题序列的最大长度\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: 模型输入的索引张量\n",
    "    \"\"\"\n",
    "    tokens = question.split()  # 分割单词\n",
    "    indices = [vocab.get(word, 0) for word in tokens]  # 将单词转为索引，未知单词映射为0\n",
    "    if len(indices) > max_len:\n",
    "        indices = indices[:max_len]  # 截断到最大长度\n",
    "    else:\n",
    "        indices += [0] * (max_len - len(indices))  # 用0填充到最大长度\n",
    "    return torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # 添加 batch 维度\n",
    "\n",
    "def predict_answer(model, question, vocab, max_len=4):\n",
    "    \"\"\"\n",
    "    使用模型回答问题。\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): 已训练好的模型\n",
    "        question (str): 输入问题，例如 \"Pine ISA Tree\"\n",
    "        vocab (dict): 词汇表\n",
    "        max_len (int): 问题序列的最大长度\n",
    "    \n",
    "    Returns:\n",
    "        str: 模型的回答 (\"Yes\" 或 \"No\")\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换到评估模式\n",
    "    with torch.no_grad():\n",
    "        # 预处理输入问题\n",
    "        input_tensor = preprocess_question(question, vocab, max_len)\n",
    "        # 模型预测\n",
    "        output = model(input_tensor).squeeze().item()  # 输出概率\n",
    "        # 根据阈值确定回答\n",
    "        return 1 if output > 0.5 else 0\n",
    "\n",
    "True_questions = []\n",
    "questions = qa_df['Question'].values  # 问题列表\n",
    "answers = qa_df['Answer'].map({\"Yes\": 1, \"No\": 0}).values  # 标签列表，\"Yes\" -> 1, \"No\" -> 0\n",
    "print(questions)\n",
    "print(answers[0])\n",
    "# Ensure answers is iterable\n",
    "for i in range(len(questions)):\n",
    "    if np.int64(answers[i]) == np.int64(1):  # Corrected from 'answer[i]' to 'answers[i]'\n",
    "        True_questions.append(questions[i])\n",
    "\n",
    "print(True_questions)\n",
    "# 初始化一个列表来存储反转后的句子\n",
    "reversed_questions = []\n",
    "\n",
    "# 遍历 Anti_questions 列表并处理每个句子\n",
    "for question in True_questions:\n",
    "    parts = question.split()  # 按空格分割句子\n",
    "    if \"ISA\" in parts:\n",
    "        # 处理含 \"ISA\" 的句子\n",
    "        idx = parts.index(\"ISA\")\n",
    "        reversed_sentence = f\"{parts[idx+1]} ISA {parts[idx-1]}\"\n",
    "    elif \"Is\" in parts:\n",
    "        # 处理含 \"Is\" 的句子\n",
    "        idx = parts.index(\"Is\")\n",
    "        reversed_sentence = f\"{parts[idx+1]} Is {parts[idx-1]}\"\n",
    "    elif \"Can\" in parts:\n",
    "        # 处理含 \"Can\" 的句子\n",
    "        idx = parts.index(\"Can\")\n",
    "        reversed_sentence = f\"{parts[idx+1]} Can {parts[idx-1]}\"\n",
    "    elif \"Has\" in parts:\n",
    "        # 处理含 \"Has\" 的句子\n",
    "        idx = parts.index(\"Has\")\n",
    "        reversed_sentence = f\"{parts[idx+1]} Has {parts[idx-1]}\"\n",
    "    else:\n",
    "        # 如果没有匹配到特殊关键词，保留原句\n",
    "        reversed_sentence = question\n",
    "\n",
    "    reversed_questions.append(reversed_sentence)\n",
    "\n",
    "# 输出反转后的句子列表\n",
    "print(reversed_questions)\n",
    "\n",
    "Answer_anti = []\n",
    "for question in reversed_questions:\n",
    "    Answer_anti.append(predict_answer(model, question, vocab, max_len=4))\n",
    "print(Answer_anti)\n",
    "\n",
    "# # # 测试代码\n",
    "# # # 假设问题是 \"Pine ISA Tree\"\n",
    "# # question = \"Red Is Rose\"\n",
    "# # answer = predict_answer(model, question, vocab, max_len=4)\n",
    "# # print(f\"Question: {question}\")\n",
    "# # print(f\"Answer: {answer}\")\n",
    "print(np.mean(Answer_anti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "592bf5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with noise level: 0.0\n",
      "Processing layer1 with noise level 0.0...\n",
      "Processing layer2 with noise level 0.0...\n",
      "Processing layer3 with noise level 0.0...\n",
      "Processing layer4 with noise level 0.0...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.01\n",
      "Processing layer1 with noise level 0.01...\n",
      "Processing layer2 with noise level 0.01...\n",
      "Processing layer3 with noise level 0.01...\n",
      "Processing layer4 with noise level 0.01...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.02\n",
      "Processing layer1 with noise level 0.02...\n",
      "Processing layer2 with noise level 0.02...\n",
      "Processing layer3 with noise level 0.02...\n",
      "Processing layer4 with noise level 0.02...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.03\n",
      "Processing layer1 with noise level 0.03...\n",
      "Processing layer2 with noise level 0.03...\n",
      "Processing layer3 with noise level 0.03...\n",
      "Processing layer4 with noise level 0.03...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.04\n",
      "Processing layer1 with noise level 0.04...\n",
      "Processing layer2 with noise level 0.04...\n",
      "Processing layer3 with noise level 0.04...\n",
      "Processing layer4 with noise level 0.04...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.05\n",
      "Processing layer1 with noise level 0.05...\n",
      "Processing layer2 with noise level 0.05...\n",
      "Processing layer3 with noise level 0.05...\n",
      "Processing layer4 with noise level 0.05...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.06\n",
      "Processing layer1 with noise level 0.06...\n",
      "Processing layer2 with noise level 0.06...\n",
      "Processing layer3 with noise level 0.06...\n",
      "Processing layer4 with noise level 0.06...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.07\n",
      "Processing layer1 with noise level 0.07...\n",
      "Processing layer2 with noise level 0.07...\n",
      "Processing layer3 with noise level 0.07...\n",
      "Processing layer4 with noise level 0.07...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.08\n",
      "Processing layer1 with noise level 0.08...\n",
      "Processing layer2 with noise level 0.08...\n",
      "Processing layer3 with noise level 0.08...\n",
      "Processing layer4 with noise level 0.08...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.09\n",
      "Processing layer1 with noise level 0.09...\n",
      "Processing layer2 with noise level 0.09...\n",
      "Processing layer3 with noise level 0.09...\n",
      "Processing layer4 with noise level 0.09...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.1\n",
      "Processing layer1 with noise level 0.1...\n",
      "Processing layer2 with noise level 0.1...\n",
      "Processing layer3 with noise level 0.1...\n",
      "Processing layer4 with noise level 0.1...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.11\n",
      "Processing layer1 with noise level 0.11...\n",
      "Processing layer2 with noise level 0.11...\n",
      "Processing layer3 with noise level 0.11...\n",
      "Processing layer4 with noise level 0.11...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.12\n",
      "Processing layer1 with noise level 0.12...\n",
      "Processing layer2 with noise level 0.12...\n",
      "Processing layer3 with noise level 0.12...\n",
      "Processing layer4 with noise level 0.12...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.13\n",
      "Processing layer1 with noise level 0.13...\n",
      "Processing layer2 with noise level 0.13...\n",
      "Processing layer3 with noise level 0.13...\n",
      "Processing layer4 with noise level 0.13...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.14\n",
      "Processing layer1 with noise level 0.14...\n",
      "Processing layer2 with noise level 0.14...\n",
      "Processing layer3 with noise level 0.14...\n",
      "Processing layer4 with noise level 0.14...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.15\n",
      "Processing layer1 with noise level 0.15...\n",
      "Processing layer2 with noise level 0.15...\n",
      "Processing layer3 with noise level 0.15...\n",
      "Processing layer4 with noise level 0.15...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.16\n",
      "Processing layer1 with noise level 0.16...\n",
      "Processing layer2 with noise level 0.16...\n",
      "Processing layer3 with noise level 0.16...\n",
      "Processing layer4 with noise level 0.16...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.17\n",
      "Processing layer1 with noise level 0.17...\n",
      "Processing layer2 with noise level 0.17...\n",
      "Processing layer3 with noise level 0.17...\n",
      "Processing layer4 with noise level 0.17...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.18\n",
      "Processing layer1 with noise level 0.18...\n",
      "Processing layer2 with noise level 0.18...\n",
      "Processing layer3 with noise level 0.18...\n",
      "Processing layer4 with noise level 0.18...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.19\n",
      "Processing layer1 with noise level 0.19...\n",
      "Processing layer2 with noise level 0.19...\n",
      "Processing layer3 with noise level 0.19...\n",
      "Processing layer4 with noise level 0.19...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.2\n",
      "Processing layer1 with noise level 0.2...\n",
      "Processing layer2 with noise level 0.2...\n",
      "Processing layer3 with noise level 0.2...\n",
      "Processing layer4 with noise level 0.2...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.21\n",
      "Processing layer1 with noise level 0.21...\n",
      "Processing layer2 with noise level 0.21...\n",
      "Processing layer3 with noise level 0.21...\n",
      "Processing layer4 with noise level 0.21...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.22\n",
      "Processing layer1 with noise level 0.22...\n",
      "Processing layer2 with noise level 0.22...\n",
      "Processing layer3 with noise level 0.22...\n",
      "Processing layer4 with noise level 0.22...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.23\n",
      "Processing layer1 with noise level 0.23...\n",
      "Processing layer2 with noise level 0.23...\n",
      "Processing layer3 with noise level 0.23...\n",
      "Processing layer4 with noise level 0.23...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.24\n",
      "Processing layer1 with noise level 0.24...\n",
      "Processing layer2 with noise level 0.24...\n",
      "Processing layer3 with noise level 0.24...\n",
      "Processing layer4 with noise level 0.24...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.25\n",
      "Processing layer1 with noise level 0.25...\n",
      "Processing layer2 with noise level 0.25...\n",
      "Processing layer3 with noise level 0.25...\n",
      "Processing layer4 with noise level 0.25...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.26\n",
      "Processing layer1 with noise level 0.26...\n",
      "Processing layer2 with noise level 0.26...\n",
      "Processing layer3 with noise level 0.26...\n",
      "Processing layer4 with noise level 0.26...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.27\n",
      "Processing layer1 with noise level 0.27...\n",
      "Processing layer2 with noise level 0.27...\n",
      "Processing layer3 with noise level 0.27...\n",
      "Processing layer4 with noise level 0.27...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.28\n",
      "Processing layer1 with noise level 0.28...\n",
      "Processing layer2 with noise level 0.28...\n",
      "Processing layer3 with noise level 0.28...\n",
      "Processing layer4 with noise level 0.28...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.29\n",
      "Processing layer1 with noise level 0.29...\n",
      "Processing layer2 with noise level 0.29...\n",
      "Processing layer3 with noise level 0.29...\n",
      "Processing layer4 with noise level 0.29...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.3\n",
      "Processing layer1 with noise level 0.3...\n",
      "Processing layer2 with noise level 0.3...\n",
      "Processing layer3 with noise level 0.3...\n",
      "Processing layer4 with noise level 0.3...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.31\n",
      "Processing layer1 with noise level 0.31...\n",
      "Processing layer2 with noise level 0.31...\n",
      "Processing layer3 with noise level 0.31...\n",
      "Processing layer4 with noise level 0.31...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.32\n",
      "Processing layer1 with noise level 0.32...\n",
      "Processing layer2 with noise level 0.32...\n",
      "Processing layer3 with noise level 0.32...\n",
      "Processing layer4 with noise level 0.32...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.33\n",
      "Processing layer1 with noise level 0.33...\n",
      "Processing layer2 with noise level 0.33...\n",
      "Processing layer3 with noise level 0.33...\n",
      "Processing layer4 with noise level 0.33...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.34\n",
      "Processing layer1 with noise level 0.34...\n",
      "Processing layer2 with noise level 0.34...\n",
      "Processing layer3 with noise level 0.34...\n",
      "Processing layer4 with noise level 0.34...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.35000000000000003\n",
      "Processing layer1 with noise level 0.35000000000000003...\n",
      "Processing layer2 with noise level 0.35000000000000003...\n",
      "Processing layer3 with noise level 0.35000000000000003...\n",
      "Processing layer4 with noise level 0.35000000000000003...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.36\n",
      "Processing layer1 with noise level 0.36...\n",
      "Processing layer2 with noise level 0.36...\n",
      "Processing layer3 with noise level 0.36...\n",
      "Processing layer4 with noise level 0.36...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.37\n",
      "Processing layer1 with noise level 0.37...\n",
      "Processing layer2 with noise level 0.37...\n",
      "Processing layer3 with noise level 0.37...\n",
      "Processing layer4 with noise level 0.37...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.38\n",
      "Processing layer1 with noise level 0.38...\n",
      "Processing layer2 with noise level 0.38...\n",
      "Processing layer3 with noise level 0.38...\n",
      "Processing layer4 with noise level 0.38...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.39\n",
      "Processing layer1 with noise level 0.39...\n",
      "Processing layer2 with noise level 0.39...\n",
      "Processing layer3 with noise level 0.39...\n",
      "Processing layer4 with noise level 0.39...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.4\n",
      "Processing layer1 with noise level 0.4...\n",
      "Processing layer2 with noise level 0.4...\n",
      "Processing layer3 with noise level 0.4...\n",
      "Processing layer4 with noise level 0.4...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.41000000000000003\n",
      "Processing layer1 with noise level 0.41000000000000003...\n",
      "Processing layer2 with noise level 0.41000000000000003...\n",
      "Processing layer3 with noise level 0.41000000000000003...\n",
      "Processing layer4 with noise level 0.41000000000000003...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.42\n",
      "Processing layer1 with noise level 0.42...\n",
      "Processing layer2 with noise level 0.42...\n",
      "Processing layer3 with noise level 0.42...\n",
      "Processing layer4 with noise level 0.42...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.43\n",
      "Processing layer1 with noise level 0.43...\n",
      "Processing layer2 with noise level 0.43...\n",
      "Processing layer3 with noise level 0.43...\n",
      "Processing layer4 with noise level 0.43...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.44\n",
      "Processing layer1 with noise level 0.44...\n",
      "Processing layer2 with noise level 0.44...\n",
      "Processing layer3 with noise level 0.44...\n",
      "Processing layer4 with noise level 0.44...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.45\n",
      "Processing layer1 with noise level 0.45...\n",
      "Processing layer2 with noise level 0.45...\n",
      "Processing layer3 with noise level 0.45...\n",
      "Processing layer4 with noise level 0.45...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.46\n",
      "Processing layer1 with noise level 0.46...\n",
      "Processing layer2 with noise level 0.46...\n",
      "Processing layer3 with noise level 0.46...\n",
      "Processing layer4 with noise level 0.46...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.47000000000000003\n",
      "Processing layer1 with noise level 0.47000000000000003...\n",
      "Processing layer2 with noise level 0.47000000000000003...\n",
      "Processing layer3 with noise level 0.47000000000000003...\n",
      "Processing layer4 with noise level 0.47000000000000003...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.48\n",
      "Processing layer1 with noise level 0.48...\n",
      "Processing layer2 with noise level 0.48...\n",
      "Processing layer3 with noise level 0.48...\n",
      "Processing layer4 with noise level 0.48...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.49\n",
      "Processing layer1 with noise level 0.49...\n",
      "Processing layer2 with noise level 0.49...\n",
      "Processing layer3 with noise level 0.49...\n",
      "Processing layer4 with noise level 0.49...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.5\n",
      "Processing layer1 with noise level 0.5...\n",
      "Processing layer2 with noise level 0.5...\n",
      "Processing layer3 with noise level 0.5...\n",
      "Processing layer4 with noise level 0.5...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.51\n",
      "Processing layer1 with noise level 0.51...\n",
      "Processing layer2 with noise level 0.51...\n",
      "Processing layer3 with noise level 0.51...\n",
      "Processing layer4 with noise level 0.51...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.52\n",
      "Processing layer1 with noise level 0.52...\n",
      "Processing layer2 with noise level 0.52...\n",
      "Processing layer3 with noise level 0.52...\n",
      "Processing layer4 with noise level 0.52...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.53\n",
      "Processing layer1 with noise level 0.53...\n",
      "Processing layer2 with noise level 0.53...\n",
      "Processing layer3 with noise level 0.53...\n",
      "Processing layer4 with noise level 0.53...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.54\n",
      "Processing layer1 with noise level 0.54...\n",
      "Processing layer2 with noise level 0.54...\n",
      "Processing layer3 with noise level 0.54...\n",
      "Processing layer4 with noise level 0.54...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.55\n",
      "Processing layer1 with noise level 0.55...\n",
      "Processing layer2 with noise level 0.55...\n",
      "Processing layer3 with noise level 0.55...\n",
      "Processing layer4 with noise level 0.55...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.56\n",
      "Processing layer1 with noise level 0.56...\n",
      "Processing layer2 with noise level 0.56...\n",
      "Processing layer3 with noise level 0.56...\n",
      "Processing layer4 with noise level 0.56...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.5700000000000001\n",
      "Processing layer1 with noise level 0.5700000000000001...\n",
      "Processing layer2 with noise level 0.5700000000000001...\n",
      "Processing layer3 with noise level 0.5700000000000001...\n",
      "Processing layer4 with noise level 0.5700000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.58\n",
      "Processing layer1 with noise level 0.58...\n",
      "Processing layer2 with noise level 0.58...\n",
      "Processing layer3 with noise level 0.58...\n",
      "Processing layer4 with noise level 0.58...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.59\n",
      "Processing layer1 with noise level 0.59...\n",
      "Processing layer2 with noise level 0.59...\n",
      "Processing layer3 with noise level 0.59...\n",
      "Processing layer4 with noise level 0.59...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.6\n",
      "Processing layer1 with noise level 0.6...\n",
      "Processing layer2 with noise level 0.6...\n",
      "Processing layer3 with noise level 0.6...\n",
      "Processing layer4 with noise level 0.6...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.61\n",
      "Processing layer1 with noise level 0.61...\n",
      "Processing layer2 with noise level 0.61...\n",
      "Processing layer3 with noise level 0.61...\n",
      "Processing layer4 with noise level 0.61...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.62\n",
      "Processing layer1 with noise level 0.62...\n",
      "Processing layer2 with noise level 0.62...\n",
      "Processing layer3 with noise level 0.62...\n",
      "Processing layer4 with noise level 0.62...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.63\n",
      "Processing layer1 with noise level 0.63...\n",
      "Processing layer2 with noise level 0.63...\n",
      "Processing layer3 with noise level 0.63...\n",
      "Processing layer4 with noise level 0.63...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.64\n",
      "Processing layer1 with noise level 0.64...\n",
      "Processing layer2 with noise level 0.64...\n",
      "Processing layer3 with noise level 0.64...\n",
      "Processing layer4 with noise level 0.64...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.65\n",
      "Processing layer1 with noise level 0.65...\n",
      "Processing layer2 with noise level 0.65...\n",
      "Processing layer3 with noise level 0.65...\n",
      "Processing layer4 with noise level 0.65...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.66\n",
      "Processing layer1 with noise level 0.66...\n",
      "Processing layer2 with noise level 0.66...\n",
      "Processing layer3 with noise level 0.66...\n",
      "Processing layer4 with noise level 0.66...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.67\n",
      "Processing layer1 with noise level 0.67...\n",
      "Processing layer2 with noise level 0.67...\n",
      "Processing layer3 with noise level 0.67...\n",
      "Processing layer4 with noise level 0.67...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.68\n",
      "Processing layer1 with noise level 0.68...\n",
      "Processing layer2 with noise level 0.68...\n",
      "Processing layer3 with noise level 0.68...\n",
      "Processing layer4 with noise level 0.68...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.6900000000000001\n",
      "Processing layer1 with noise level 0.6900000000000001...\n",
      "Processing layer2 with noise level 0.6900000000000001...\n",
      "Processing layer3 with noise level 0.6900000000000001...\n",
      "Processing layer4 with noise level 0.6900000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.7000000000000001\n",
      "Processing layer1 with noise level 0.7000000000000001...\n",
      "Processing layer2 with noise level 0.7000000000000001...\n",
      "Processing layer3 with noise level 0.7000000000000001...\n",
      "Processing layer4 with noise level 0.7000000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.71\n",
      "Processing layer1 with noise level 0.71...\n",
      "Processing layer2 with noise level 0.71...\n",
      "Processing layer3 with noise level 0.71...\n",
      "Processing layer4 with noise level 0.71...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.72\n",
      "Processing layer1 with noise level 0.72...\n",
      "Processing layer2 with noise level 0.72...\n",
      "Processing layer3 with noise level 0.72...\n",
      "Processing layer4 with noise level 0.72...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.73\n",
      "Processing layer1 with noise level 0.73...\n",
      "Processing layer2 with noise level 0.73...\n",
      "Processing layer3 with noise level 0.73...\n",
      "Processing layer4 with noise level 0.73...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.74\n",
      "Processing layer1 with noise level 0.74...\n",
      "Processing layer2 with noise level 0.74...\n",
      "Processing layer3 with noise level 0.74...\n",
      "Processing layer4 with noise level 0.74...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.75\n",
      "Processing layer1 with noise level 0.75...\n",
      "Processing layer2 with noise level 0.75...\n",
      "Processing layer3 with noise level 0.75...\n",
      "Processing layer4 with noise level 0.75...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.76\n",
      "Processing layer1 with noise level 0.76...\n",
      "Processing layer2 with noise level 0.76...\n",
      "Processing layer3 with noise level 0.76...\n",
      "Processing layer4 with noise level 0.76...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.77\n",
      "Processing layer1 with noise level 0.77...\n",
      "Processing layer2 with noise level 0.77...\n",
      "Processing layer3 with noise level 0.77...\n",
      "Processing layer4 with noise level 0.77...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.78\n",
      "Processing layer1 with noise level 0.78...\n",
      "Processing layer2 with noise level 0.78...\n",
      "Processing layer3 with noise level 0.78...\n",
      "Processing layer4 with noise level 0.78...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.79\n",
      "Processing layer1 with noise level 0.79...\n",
      "Processing layer2 with noise level 0.79...\n",
      "Processing layer3 with noise level 0.79...\n",
      "Processing layer4 with noise level 0.79...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.8\n",
      "Processing layer1 with noise level 0.8...\n",
      "Processing layer2 with noise level 0.8...\n",
      "Processing layer3 with noise level 0.8...\n",
      "Processing layer4 with noise level 0.8...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.81\n",
      "Processing layer1 with noise level 0.81...\n",
      "Processing layer2 with noise level 0.81...\n",
      "Processing layer3 with noise level 0.81...\n",
      "Processing layer4 with noise level 0.81...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.8200000000000001\n",
      "Processing layer1 with noise level 0.8200000000000001...\n",
      "Processing layer2 with noise level 0.8200000000000001...\n",
      "Processing layer3 with noise level 0.8200000000000001...\n",
      "Processing layer4 with noise level 0.8200000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.8300000000000001\n",
      "Processing layer1 with noise level 0.8300000000000001...\n",
      "Processing layer2 with noise level 0.8300000000000001...\n",
      "Processing layer3 with noise level 0.8300000000000001...\n",
      "Processing layer4 with noise level 0.8300000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.84\n",
      "Processing layer1 with noise level 0.84...\n",
      "Processing layer2 with noise level 0.84...\n",
      "Processing layer3 with noise level 0.84...\n",
      "Processing layer4 with noise level 0.84...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.85\n",
      "Processing layer1 with noise level 0.85...\n",
      "Processing layer2 with noise level 0.85...\n",
      "Processing layer3 with noise level 0.85...\n",
      "Processing layer4 with noise level 0.85...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.86\n",
      "Processing layer1 with noise level 0.86...\n",
      "Processing layer2 with noise level 0.86...\n",
      "Processing layer3 with noise level 0.86...\n",
      "Processing layer4 with noise level 0.86...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.87\n",
      "Processing layer1 with noise level 0.87...\n",
      "Processing layer2 with noise level 0.87...\n",
      "Processing layer3 with noise level 0.87...\n",
      "Processing layer4 with noise level 0.87...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.88\n",
      "Processing layer1 with noise level 0.88...\n",
      "Processing layer2 with noise level 0.88...\n",
      "Processing layer3 with noise level 0.88...\n",
      "Processing layer4 with noise level 0.88...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.89\n",
      "Processing layer1 with noise level 0.89...\n",
      "Processing layer2 with noise level 0.89...\n",
      "Processing layer3 with noise level 0.89...\n",
      "Processing layer4 with noise level 0.89...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.9\n",
      "Processing layer1 with noise level 0.9...\n",
      "Processing layer2 with noise level 0.9...\n",
      "Processing layer3 with noise level 0.9...\n",
      "Processing layer4 with noise level 0.9...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.91\n",
      "Processing layer1 with noise level 0.91...\n",
      "Processing layer2 with noise level 0.91...\n",
      "Processing layer3 with noise level 0.91...\n",
      "Processing layer4 with noise level 0.91...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.92\n",
      "Processing layer1 with noise level 0.92...\n",
      "Processing layer2 with noise level 0.92...\n",
      "Processing layer3 with noise level 0.92...\n",
      "Processing layer4 with noise level 0.92...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.93\n",
      "Processing layer1 with noise level 0.93...\n",
      "Processing layer2 with noise level 0.93...\n",
      "Processing layer3 with noise level 0.93...\n",
      "Processing layer4 with noise level 0.93...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.9400000000000001\n",
      "Processing layer1 with noise level 0.9400000000000001...\n",
      "Processing layer2 with noise level 0.9400000000000001...\n",
      "Processing layer3 with noise level 0.9400000000000001...\n",
      "Processing layer4 with noise level 0.9400000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.9500000000000001\n",
      "Processing layer1 with noise level 0.9500000000000001...\n",
      "Processing layer2 with noise level 0.9500000000000001...\n",
      "Processing layer3 with noise level 0.9500000000000001...\n",
      "Processing layer4 with noise level 0.9500000000000001...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.96\n",
      "Processing layer1 with noise level 0.96...\n",
      "Processing layer2 with noise level 0.96...\n",
      "Processing layer3 with noise level 0.96...\n",
      "Processing layer4 with noise level 0.96...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.97\n",
      "Processing layer1 with noise level 0.97...\n",
      "Processing layer2 with noise level 0.97...\n",
      "Processing layer3 with noise level 0.97...\n",
      "Processing layer4 with noise level 0.97...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.98\n",
      "Processing layer1 with noise level 0.98...\n",
      "Processing layer2 with noise level 0.98...\n",
      "Processing layer3 with noise level 0.98...\n",
      "Processing layer4 with noise level 0.98...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 0.99\n",
      "Processing layer1 with noise level 0.99...\n",
      "Processing layer2 with noise level 0.99...\n",
      "Processing layer3 with noise level 0.99...\n",
      "Processing layer4 with noise level 0.99...\n",
      "Embedding layer restored to original weights.\n",
      "\n",
      "Evaluating model with noise level: 1.0\n",
      "Processing layer1 with noise level 1.0...\n",
      "Processing layer2 with noise level 1.0...\n",
      "Processing layer3 with noise level 1.0...\n",
      "Processing layer4 with noise level 1.0...\n",
      "Embedding layer restored to original weights.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def add_noise_to_embeddings(model, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    在模型嵌入层添加噪声，模拟语义退化。\n",
    "    \n",
    "    Args:\n",
    "        model: 已训练的模型\n",
    "        noise_level: 噪声强度（标准差）\n",
    "    \n",
    "    Returns:\n",
    "        embeddings_with_noise: 添加噪声后的嵌入权重\n",
    "        embeddings_original: 原始嵌入权重的独立副本\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 获取嵌入层权重\n",
    "        embeddings = model.embedding.weight\n",
    "        \n",
    "        # 生成与权重形状相同的噪声\n",
    "        noise = torch.randn_like(embeddings) * noise_level\n",
    "        \n",
    "        # 保存原始权重的独立副本\n",
    "        embeddings_original = embeddings.detach().clone()  # 深拷贝\n",
    "        \n",
    "        # 添加噪声到嵌入层\n",
    "        embeddings_with_noise = embeddings + noise\n",
    "    \n",
    "    return embeddings_with_noise, embeddings_original\n",
    "\n",
    "def extract_predictions_with_embedding_noise(model, questions, layers, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    提取在嵌入层加噪声后的问题的预测结果。\n",
    "    \n",
    "    Args:\n",
    "        model: 已训练的模型\n",
    "        questions: 查询问题列表（按层次组织的字典）\n",
    "        layers: 要处理的层名称列表\n",
    "        noise_level: 噪声强度（标准差）\n",
    "    \n",
    "    Returns:\n",
    "        predictions_dict: 每个层和问题的预测结果\n",
    "    \"\"\"\n",
    "    predictions_dict = {}\n",
    "    \n",
    "    # 添加噪声到嵌入层\n",
    "    embeddings_with_noise, embeddings_original = add_noise_to_embeddings(model, noise_level=noise_level)\n",
    "    \n",
    "    # 替换嵌入层权重\n",
    "    model.embedding.weight.data.copy_(embeddings_with_noise)\n",
    "    \n",
    "    for layer in layers:\n",
    "        print(f\"Processing {layer} with noise level {noise_level}...\")\n",
    "        \n",
    "        # 获取该层的问题列表\n",
    "        layer_questions = questions[layer]\n",
    "        \n",
    "        # 转换问题为模型输入\n",
    "        max_len = 4  # 假设问题的最大长度\n",
    "        encoded_questions = np.array([one_hot_encode_question(q, vocab, max_len) for q in layer_questions])\n",
    "        question_tensors = torch.tensor(encoded_questions, dtype=torch.long).to(device)\n",
    "        \n",
    "        # 获取模型预测\n",
    "        with torch.no_grad():\n",
    "            outputs = model(question_tensors).squeeze()\n",
    "            predictions = (outputs).float().cpu().numpy()  # 二分类阈值 > 0.5\n",
    "        \n",
    "        # 保存当前层的预测结果\n",
    "        predictions_dict[layer] = {\n",
    "            \"questions\": layer_questions,\n",
    "            \"predictions\": predictions\n",
    "        }\n",
    "    \n",
    "    # 恢复嵌入层的原始权重\n",
    "    model.embedding.weight.data.copy_(embeddings_original)\n",
    "    print(\"Embedding layer restored to original weights.\")\n",
    "    \n",
    "    return predictions_dict\n",
    "\n",
    "# 使用 create_query_questions 函数生成层问题\n",
    "layer1_questions, layer2_questions, layer3_questions, layer4_questions = create_query_questions()\n",
    "\n",
    "# 将层问题组织成字典\n",
    "questions = {\n",
    "    \"layer1\": layer1_questions,\n",
    "    \"layer2\": layer2_questions,\n",
    "    \"layer3\": layer3_questions,\n",
    "    \"layer4\": layer4_questions\n",
    "}\n",
    "\n",
    "# 提取在嵌入层加噪声后的预测结果\n",
    "layers = [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]\n",
    "noise_levels = np.arange(0.0, 1.01, 0.01)  # 定义噪声强度\n",
    "degraded_results = {}\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    print(f\"\\nEvaluating model with noise level: {noise_level}\")\n",
    "    \n",
    "    # 提取预测结果\n",
    "    embedding_noise_predictions = extract_predictions_with_embedding_noise(model, questions, layers, noise_level)\n",
    "    \n",
    "    # 保存预测结果到文件\n",
    "    save_results(embedding_noise_predictions, f\"embedding_layer_noise_predictions_{noise_level}.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1016FP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
